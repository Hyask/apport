#!/usr/bin/python

import os, time, optparse, subprocess

from launchpadBugs.HTMLOperations import Bug, BugList
from apport.crashdb import get_crashdb

arch_tag_map = {
    'i386': 'need-i386-retrace',
    'i686': 'need-i386-retrace',
    'x86_64': 'need-amd64-retrace',
    'ppc': 'need-powerpc-retrace',
    'ppc64': 'need-powerpc-retrace',
}

#
# classes
#

class Struct:
    '''Convenience class for creating on-the-fly anonymous objects.'''

    def __init__(self, **entries): 
        self.__dict__.update(entries)

class CrashDigger:
    def __init__(self, chroot_map, cookie_file, verbose=False, sleep_time=600,
        dup_db=None):
        '''Initialize work pool.'''

        self.arch_tag = arch_tag_map[os.uname()[4]]
        self.list_url = 'https://launchpad.net/ubuntu/+bugs?field.tag=' + self.arch_tag
        self.work_pool = set()
        self.fail_pool = set()
        self.verbose = verbose
        self.chroot_map = chroot_map
        self.cookie_file = cookie_file
        self.sleep_time = sleep_time
        self.dup_db = dup_db
        self.log('Initializing crash digger to process bugs on %s, using chroot map %s' % (
            self.list_url, self.chroot_map))

	# read chroot map and get available releases
	m = eval(open(self.chroot_map).read(), {}, {})
	self.releases = m.keys()
	self.log('Available releases: %s' % str(self.releases))

	self.crashdb = get_crashdb(cookie_file)

        if self.dup_db:
            self.crashdb.init_duplicate_db(self.dup_db)

    def log(self, str):
        '''If verbosity is enabled, log the given string to stdout, and prepend
        the current date and time.'''

        if self.verbose:
            print '%s: %s' % (time.strftime('%x %X'), str)

    def fill_pool(self):
        '''Query Launchpad for new crash bugs for our processor
        architecture.
        
        This function also takes care of regularly consolidating the duplicate
        database.'''

        if self.dup_db:
            if self.crashdb.duplicate_db_needs_consolidation():
                self.log('Consolidating duplicate database...')
                self.crashdb.duplicate_db_consolidate()
                if self.verbose:
                    print 'duplicate db is now:'
                    print '-------------'
                    for k, v in self.crashdb._duplicate_db_dump(True):
                        print k, v
                    print '-------------'

        bugs = set()
        # get set of bug list integers (.bugs is a list of Bug objects)
        for b in BugList(Struct(url = self.list_url, upstream = None, tag=None,
            minbug = None, filterbug = None, status = '', importance = '',
	    closed_bugs=None, duplicates=None, lastcomment=None)).bugs:
            bugs.add(int(b))
        bugs -= self.fail_pool
        self.work_pool.update(bugs)

        self.log('fill_pool: got new bugs %s' % str(bugs))
        self.log('fill_pool: work pool now: %s' % str(self.work_pool))
        self.log('fill_pool: fail pool now: %s' % str(self.fail_pool))

    def retrace_next(self):
        '''Grab a bug from the work pool and retrace it.'''

        bug = self.work_pool.pop()
        self.log('retracing bug %i' % bug)

        try:
            rel = self.crashdb.get_distro_release(bug)
        except ValueError:
	    self.log('could not determine release of bug -- no DistroRelease field?')
            self.fail_pool.add(bug)
	    return
	if rel not in self.releases:
	    self.log('bug is release %s which does not have a chroot available, skipping' % rel)
            self.fail_pool.add(bug)
	    return

        # remove tag
        b = Bug(bug, None, cookie_file=self.cookie_file)
        b.get_metadata()
        if self.arch_tag in b.tags:
            b.tags.remove(self.arch_tag)
            b.set_metadata()

        argv = ['apport-chroot', '-m', self.chroot_map, '--auth',
            self.cookie_file]
        if self.dup_db:
            argv += ['--duplicate-db', self.dup_db]
        argv += ['retrace', str(bug)]

        result = subprocess.call(argv)
        self.log('retracing bug %i exit status: %i' % (bug, result))
        if result != 0:
            self.fail_pool.add(bug)

    def run(self):
        '''Process the entire work pool until it is empty and get new entries
        afterwards.

        Sleep if no new items are available. This function never returns.'''

        while True:
            while self.work_pool:
                self.retrace_next()
            self.fill_pool()
            if not self.work_pool:
                self.log('work pool empty, sleeping for %i seconds' % self.sleep_time)
                time.sleep(self.sleep_time)

#
# functions
#

def parse_options():
    '''Parse command line options and return (options, args) tuple.'''

    optparser = optparse.OptionParser('%prog [options]')
    optparser.add_option('-m', '--chroot-map',
        help='Path to chroot map. This is a file that defines a Python dictionary, mapping DistroRelease: values to chroot paths',
        action='store', type='string', dest='chroot_map', metavar='FILE', default=None)
    optparser.add_option('-c', '--cookie',
        help='Path to a Mozilla-style cookie file, for doing Launchpad bug changes',
        action='store', type='string', dest='cookie_file', default=None)
    optparser.add_option('-s', '--sleep',
        help='Number of seconds to sleep when the work queue is empty (default: 600)',
        action='store', type='int', dest='sleep', metavar='SECONDS', default=600)
    optparser.add_option('-d', '--duplicate-db',
        help='Path to the duplicate sqlite database (default: disabled)',
        action='store', type='string', dest='dup_db', metavar='PATH',
        default=None)
    optparser.add_option('-v', '--verbose',
        help='Verbose operation (also passed to apport-retrace)',
        action='store_true', dest='verbose', default=False)

    (opts, args) = optparser.parse_args()

    assert opts.chroot_map
    assert opts.cookie_file

    return (opts, args)

#
# main
#

opts, args = parse_options()
CrashDigger(opts.chroot_map, opts.cookie_file, opts.verbose, opts.sleep,
    opts.dup_db).run()
